"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2414],{2211:(r,e,n)=>{n.r(e),n.d(e,{assets:()=>d,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"time-forcasting/others","title":"others","description":"\u5176\u4ed6\u884c\u4e1a","source":"@site/docs/time-forcasting/others.md","sourceDirName":"time-forcasting","slug":"/time-forcasting/others","permalink":"/docs/time-forcasting/others","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"cruise","permalink":"/docs/time-forcasting/cruise"},"next":{"title":"precipitation","permalink":"/docs/time-forcasting/precipitation"}}');var i=n(4848),a=n(8453);const s={},o=void 0,d={},c=[{value:"\u5176\u4ed6\u884c\u4e1a",id:"\u5176\u4ed6\u884c\u4e1a",level:2},{value:"MINST",id:"minst",level:4}];function l(r){const e={code:"code",h2:"h2",h4:"h4",p:"p",pre:"pre",...(0,a.R)(),...r.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h2,{id:"\u5176\u4ed6\u884c\u4e1a",children:"\u5176\u4ed6\u884c\u4e1a"}),"\n",(0,i.jsx)(e.p,{children:"[\u6e90\u4ee3\u7801(\u674e\u6d77\u519b)](../../lhj.zip"}),"\n",(0,i.jsx)(e.p,{children:"[\u6e90\u4ee3\u7801(\u9773\u667a\u6021](../../jzy.zip"}),"\n",(0,i.jsx)(e.p,{children:"[\u6e90\u4ee3\u7801(resnet](../../resnet.zip"}),"\n",(0,i.jsx)(e.p,{children:"[\u6e90\u4ee3\u7801(senet](../../senet.zip"}),"\n",(0,i.jsx)(e.p,{children:"[\u6e90\u4ee3\u7801(sknet](../../sknet.zip"}),"\n",(0,i.jsx)(e.p,{children:"\u6570\u636e\u5904\u7406"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-py",children:'import numpy as np\r\nimport pandas as pd\r\nimport seaborn as sns\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n# set [ value & label ] align\r\npd.set_option(\'display.unicode.ambiguous_as_wide\', True)\r\npd.set_option(\'display.unicode.east_asian_width\', True)\r\n\r\n# read data\r\ndf = pd.read_csv(\'./data.csv\')\r\n\r\n# show data\r\nprint(df.to_string())\r\n((df.isnull().sum())/df.shape[0]).sort_values(ascending=False).map(lambda x:"{:.2%}".format(x))\r\n# For feature \'\u957f\' and \'\u5bbd\', it\'s same in every samples, so drop it.\r\ndf = df.drop("\u957f", axis=1)\r\ndf = df.drop("\u5bbd", axis=1)\r\n\r\n# Show changed data\r\nprint(df.to_string())\r\ndf["\u7c7b\u578b"] = df["\u7c7b\u578b"].replace({"\u6728": 0, "\u94f8\u94c1": 1})\r\ndf["\u6f0f\u6597\u7c7b\u578b"] = df["\u6f0f\u6597\u7c7b\u578b"].replace({"\u5706\u5f62": 0, "\u692d\u5706\u5f62": 1, "\u692d\u5706": 1})\r\ndf.fillna(0, inplace=True)\r\nprint(df.to_string())\r\n# Change data type:\'  From object to the type below.\r\ndf[\'\u6f0f\u6597\u7c7b\u578b\'] = pd.to_numeric(df[\'\u6f0f\u6597\u7c7b\u578b\'], errors=\'coerce\')\r\nprint(df.dtypes)\n'})}),"\n",(0,i.jsx)(e.p,{children:"\u5f52\u4e00\u5316"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-py",children:"# Create MinMaxScaler\r\n# Use Max-Min-Normalization\r\nscaler = MinMaxScaler()\r\ndf_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\r\n\r\n# Show data\r\nprint(df_normalized.to_string())\r\nx = df_normalized.drop(columns='\u6f0f\u6597\u7c7b\u578b')\r\ny = df_normalized['\u6f0f\u6597\u7c7b\u578b']\r\n# segment data to four part -> train & test\r\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-py",children:"# Save data to ../set\r\nx_train.to_csv('../set/x_train.csv', index=False)\r\nx_test.to_csv('../set/x_test.csv', index=False)\r\ny_train.to_csv('../set/y_train.csv', index=False)\r\ny_test.to_csv('../set/y_test.csv', index=False)\r\n# \u8ba1\u7b97\u76f8\u5173\u7cfb\u6570\u77e9\u9635\r\ncorrelation_matrix = df_normalized.corr(method='pearson')\r\nprint(correlation_matrix.to_string())\r\nimport matplotlib\r\n\r\n# \u8bbe\u7f6e\u5b57\u4f53\u4e3a\u652f\u6301\u4e2d\u6587\u7684\u5b57\u4f53\r\nmatplotlib.rcParams['font.family'] = 'Microsoft YaHei'\r\n\r\nplt.figure(figsize=(8, 6))\r\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\r\nplt.title('\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u70ed\u56fe')\r\nplt.show()\n"})}),"\n",(0,i.jsx)(e.h4,{id:"minst",children:"MINST"}),"\n",(0,i.jsx)(e.p,{children:"\u8fd9\u6bb5\u4ee3\u7801\u662f\u7528\u4e8e\u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u6a21\u578b\uff0c\u76ee\u7684\u662f\u8bc6\u522b\u624b\u5199\u6570\u5b57\uff08MNIST\u6570\u636e\u96c6\uff09"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-py",children:"(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\r\n\r\ntrain_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\r\ntest_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense(64, activation='relu'))\r\nmodel.add(layers.Dense(10, activation='softmax'))\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\r\n\r\nmodel.save('digit_recognition_model.h5')\n"})}),"\n",(0,i.jsx)(e.p,{children:"\u8bad\u7ec3\u8fc7\u7a0b"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-py",children:'import numpy as np\r\nimport cv2\r\nfrom PIL import ImageGrab\r\nfrom tensorflow.keras.models import load_model\r\n\r\nmodel = load_model(\'digit_recognition_model.h5\')\r\ndef capture_screen(region):\r\n    screen = ImageGrab.grab(bbox=region)\r\n    # screen = Image.open("./image.png")\r\n    return np.array(screen)\r\n\r\n\r\ndef preprocess_image(image):\r\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \r\n    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV) \r\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\r\n    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\r\n    return processed\r\n\r\n\r\ndef find_contours(image):\r\n    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n    return contours\r\n\r\n\r\ndef extract_digits(image, contours):\r\n    digit_images = []\r\n    for contour in contours:\r\n        x, y, w, h = cv2.boundingRect(contour)\r\n        if w > 10 and h > 20 and h < 100: \r\n            roi = image[y : y + h, x : x + w]\r\n            digit_images.append((x, roi))\r\n\r\n    digit_images = sorted(digit_images, key=lambda item: item[0])\r\n    return [digit[1] for digit in digit_images]\r\n\r\n\r\ndef recognize_digit(image):\r\n    resized = cv2.resize(image, (28, 28))\r\n    normalized = resized / 255.0\r\n    reshaped = normalized.reshape(1, 28, 28, 1)\r\n    prediction = model.predict(reshaped)\r\n    return np.argmax(prediction)\r\n\r\n\r\ndef recognize_digits(image):\r\n    contours = find_contours(image)\r\n    digit_images = extract_digits(image, contours)\r\n    recognized_digits = [recognize_digit(digit) for digit in digit_images]\r\n    return "".join(map(str, recognized_digits))\r\n\r\nimport pyautogui\r\ndef getDigital(region):\r\n    screenshot = capture_screen(region)\r\n    preprocessed_image = preprocess_image(screenshot)\r\n    recognized_digits = recognize_digits(preprocessed_image)\r\n    return recognize_digit\r\n\r\n\r\ndef draw_greater_than(start_x, start_y):\r\n    pyautogui.moveTo(start_x, start_y)\r\n    pyautogui.mouseDown()\r\n    pyautogui.mouseDown()\r\n    pyautogui.moveTo(start_x + 100, start_y - 100, duration=0.1)  # \u53f3\u4e0a\r\n    pyautogui.moveTo(start_x + 100, start_y + 100, duration=0.1)  # \u53f3\u4e0b\r\n    pyautogui.moveTo(start_x, start_y, duration=0.3)  # \u5de6\u4e0a\r\n    pyautogui.mouseUp()\r\n\r\n\r\ndef draw_less_than(start_x, start_y):\r\n    pyautogui.moveTo(start_x, start_y)\r\n    pyautogui.mouseDown()\r\n    pyautogui.mouseDown()\r\n    pyautogui.moveTo(start_x - 100, start_y - 100, duration=0.1)  # \u5de6\u4e0a\r\n    pyautogui.moveTo(start_x - 100, start_y + 100, duration=0.1)  # \u5de6\u4e0b\r\n    pyautogui.moveTo(start_x, start_y, duration=0.3)  # \u53f3\u4e0a\r\n    pyautogui.mouseUp()\r\n    \r\nwhile(True):\r\n    region_1 = (247, 326, 292, 386)\r\n    region_2 = (399, 323, 474, 395)\r\n    num_1 = recognize_digit(region_1)\r\n    num_2 = recognize_digit(region_2)\r\n    print(num_1)\r\n    print(num_2)\r\n    if num_1 > num_2:\r\n        draw_greater_than(333, 482)\r\n    else:\r\n        draw_less_than(333, 482)\n'})})]})}function m(r={}){const{wrapper:e}={...(0,a.R)(),...r.components};return e?(0,i.jsx)(e,{...r,children:(0,i.jsx)(l,{...r})}):l(r)}},8453:(r,e,n)=>{n.d(e,{R:()=>s,x:()=>o});var t=n(6540);const i={},a=t.createContext(i);function s(r){const e=t.useContext(a);return t.useMemo((function(){return"function"==typeof r?r(e):{...e,...r}}),[e,r])}function o(r){let e;return e=r.disableParentContext?"function"==typeof r.components?r.components(i):r.components||i:s(r.components),t.createElement(a.Provider,{value:e},r.children)}}}]);