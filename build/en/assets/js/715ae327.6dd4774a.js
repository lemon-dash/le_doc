"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7124],{4547:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"time-forcasting/cruise","title":"cruise","description":"\u822a\u6d77\u5927\u6570\u636e","source":"@site/docs/time-forcasting/cruise.md","sourceDirName":"time-forcasting","slug":"/time-forcasting/cruise","permalink":"/en/docs/time-forcasting/cruise","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"agriculture","permalink":"/en/docs/time-forcasting/agriculture"},"next":{"title":"others","permalink":"/en/docs/time-forcasting/others"}}');var r=t(4848),l=t(8453);const a={},i=void 0,o={},d=[{value:"\u822a\u6d77\u5927\u6570\u636e",id:"\u822a\u6d77\u5927\u6570\u636e",level:2},{value:"BiGRU",id:"BiGRU",level:4},{value:"BiLSTM",id:"BiLSTM",level:4},{value:"BP",id:"BP",level:4},{value:"CNN-GRU",id:"CG",level:4},{value:"CNN-LSTM",id:"CL",level:4},{value:"CNN-LSTM-Att",id:"CLA",level:4},{value:"GRU",id:"GRU",level:4},{value:"LSTM",id:"LSTM",level:4},{value:"RNN-LSTM",id:"RL",level:4},{value:"RNN-LSTM-Att",id:"RLA",level:4},{value:"TCN-ABiLSTM",id:"TABL",level:4},{value:"\u7f16\u7801\u89e3\u7801-LSTM",id:"EDL",level:4},{value:"STA-GRU",id:"SG",level:4},{value:"SW-BiLSTM",id:"SBL",level:4}];function c(e){const n={a:"a",code:"code",h2:"h2",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"\u822a\u6d77\u5927\u6570\u636e",children:"\u822a\u6d77\u5927\u6570\u636e"}),"\n",(0,r.jsx)(n.p,{children:"[\u6e90\u4ee3\u7801\u4e0b\u8f7d](../../cruise.zip"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#BiLSTM",children:"BiLSTM"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#BP",children:"BP"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#CG",children:"CNN-GRU"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#CL",children:"CNN-LSTM"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#CLA",children:"CNN-LSTM-Attention"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#GRU",children:"GRU"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#LSTM",children:"LSTM"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#RL",children:"RNN-LSTM"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#RLA",children:"RNN-LSTM-Attention"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#TABL",children:"TCN-ABiLSTM"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#EDL",children:"\u7f16\u7801\u89e3\u7801-LSTM"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#SG",children:"STA-GRU"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#SBL",children:"SW-BiLSTM"})}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"BiGRU",children:"BiGRU"}),"\n",(0,r.jsx)(n.p,{children:"\u5bfc\u5165\u8bbe\u7f6e"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers import LSTM\nfrom keras.models import Sequential, load_model\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau\nfrom keras.optimizers import adam_v2\n# import transbigdata as tbd\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nnp.random.seed(120)\ntf.random.set_seed(120)\n# \u652f\u6301\u4e2d\u6587\nplt.rcParams['font.sans-serif'] = ['SimHei']  # \u7528\u6765\u6b63\u5e38\u663e\u793a\u4e2d\u6587\u6807\u7b7e\nplt.rcParams['axes.unicode_minus'] = False  # \u7528\u6765\u6b63\u5e38\u663e\u793a\u8d1f\u53f7\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u8ddd\u79bb\u8bef\u5dee\u51fd\u6570"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"def hav(theta):\n    s = np.sin(theta / 2)\n    return s * s\n\ndef get_distance_hav(lat0, lng0, lat1, lng1):\n    EARTH_RADIUS = 6371\n    lat0 = np.radians(lat0)\n    lat1 = np.radians(lat1)\n    lng0 = np.radians(lng0)\n    lng1 = np.radians(lng1)\n\n    dlng = np.fabs(lng0 - lng1)\n    dlat = np.fabs(lat0 - lat1)\n    h = hav(dlat) + np.cos(lat0) * np.cos(lat1) * hav(dlng)\n    distance = 2 * EARTH_RADIUS * np.arcsin(np.sqrt(h))\n    return distance\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u7528\u4e8e\u521b\u9020\u8bad\u7ec3\u96c6\u6253\u9020\u6807\u7b7e"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"def createSequence(data, window=10, maxmin=None):\n    train_seq = []\n    train_label = []\n    m, n = maxmin\n    for traj_id in set(data['mmsi']):\n        data_temp = data.loc[data.mmsi == traj_id]\n        first_lon = data_temp.loc[0, 'lon']\n        first_lat = data_temp.loc[0, 'lat']\n        end_lon = data_temp.loc[data_temp.shape[0] - 1, 'lon']\n        end_lat = data_temp.loc[data_temp.shape[0] - 1, 'lat']\n\n        data_temp = np.array(data_temp.loc[:, ['lon', 'lat', 'sog', 'cog']])\n        # \u6807\u51c6\u5316\n        data_temp = (data_temp - n) / (m - n)\n\n        for i in range(data_temp.shape[0] - window):\n            x = []\n            for j in range(i, i + window):\n                x.append(list(data_temp[j, :]))\n            train_seq.append(x)\n            train_label.append(data_temp[i + window, :])\n\n    train_seq = np.array(train_seq, dtype='float64')\n    train_label = np.array(train_label, dtype='float64')\n\n    return train_seq, train_label\n\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u591a\u7ef4\u53cd\u5f52\u4e00\u5316"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# \u591a\u7ef4\u53cd\u5f52\u4e00\u5316\ndef FNormalizeMult(y_pre, y_true, max_min):\n    [m1, n1, s1, c1], [m2, n2, s2, c2] = max_min\n    y_pre[:, 0] = y_pre[:, 0] * (m1 - m2) + m2\n    y_pre[:, 1] = y_pre[:, 1] * (n1 - n2) + n2\n    y_pre[:, 2] = y_pre[:, 2] * (s1 - s2) + s2\n    y_pre[:, 3] = y_pre[:, 3] * (c1 - c2) + c2\n    y_true[:, 0] = y_true[:, 0] * (m1 - m2) + m2\n    y_true[:, 1] = y_true[:, 1] * (n1 - n2) + n2\n    y_true[:, 2] = y_true[:, 2] * (s1 - s2) + s2\n    y_true[:, 3] = y_true[:, 3] * (c1 - c2) + c2\n\n    # \u8ba1\u7b97\u8ddd\u79bb\n    y_pre = np.insert(y_pre, y_pre.shape[1],\n                      get_distance_hav(y_true[:, 1], y_true[:, 0], y_pre[:, 1], y_pre[:, 0]), axis=1)\n\n    return y_pre, y_true\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u53cc\u5411GRU\u5c42\uff0c\u5305\u542b108\u4e2a\u5355\u5143\u3002\xa0return_sequences=False\xa0\u53c2\u6570\u610f\u5473\u7740GRU\u5c42\u7684\u8f93\u51fa\u5c06\u53ea\u8fd4\u56de\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\uff0c\u800c\u4e0d\u662f\u8fd4\u56de\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\u5e8f\u5217\u3002\u6a21\u578b\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u4e3aAdam\uff0c\u5e76\u4e14\u76d1\u63a7\u51c6\u786e\u7387\uff08accuracy\uff09\u4f5c\u4e3a\u6027\u80fd\u6307\u6807\u3002\n\u8fd9\u4e2a\u7f51\u7edc\u7ed3\u6784\u9002\u7528\u4e8e\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\uff0c\u4f8b\u5982\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\uff0c\u5176\u4e2d\u53cc\u5411GRU\u5c42\u53ef\u4ee5\u6355\u6349\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u3002"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'title="\u53cc\u5411GRU\u7f51\u7edc"',children:"from keras.layers import GRU\nfrom keras.layers import Bidirectional\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    model.add(Bidirectional(GRU(108, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False)))\n    # model.add(Dropout(0.3))\n    model.add(Dense(train_Y.shape[1]))\n    model.add(Activation(\"relu\"))\n    adam = adam_v2.Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    # Save the changes to the log\n    log = CSVLogger(f\"./log50\u70bc\u4e391123.csv\", separator=\",\", append=True)\n    # Reducing learning rate on a plateau\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1,\n                               mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n    # Model training\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1,\n                  callbacks=[log, reduce])\n    # Evaluate with the test set\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    # Save the model\n    model.save(f\"./bigru_50_model\u70bc\u4e391123.h5\")\n    # Print the neural network structure and count the parameters\n    model.summary()\n    return model\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u8bad\u7ec3\u8fc7\u7a0b"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# \u83b7\u53d6\u6570\u636e\ntrain = pd.read_csv(\"./train.csv\",index_col=0)\ntest = pd.read_csv(\"./test.csv\",index_col=0)\ntrain.head()\n\n# \u8ba1\u7b97\u5f52\u4e00\u5316\u53c2\u6570\nnor = np.array(train.loc[:, ['lon', 'lat', 'sog', 'cog']])\nm = nor.max(axis=0)\nn = nor.min(axis=0)\nmaxmin = [m, n]\n\n# \u6b65\u957f\nwindows = 10\ntrain_seq, train_label = createSequence(train, windows, maxmin)\ntest_seq, test_label = createSequence(test, windows, maxmin)\n# \u8bad\u7ec3\u6a21\u578b\nmodel = trainModel(train_seq, train_label,test_seq,test_label)\n# model = load_model(\"./bigru_50_model\u70bc\u4e392.h5\")\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u7ed8\u5236\u8bad\u7ec3\u7ed3\u679c"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"logs = pd.read_csv(\"./log50\u70bc\u4e391123.csv\")\n\nfig, ax = plt.subplots(2,2,figsize=(15,8))\nax[0][0].plot(logs['epoch'],logs['acc'], label='acc')\nax[0][0].set_title('acc')\n\nax[0][1].plot(logs['epoch'],logs['loss'], label='loss')\nax[0][1].set_title('loss')\n\nax[1][0].plot(logs['epoch'],logs['val_acc'], label='val_acc')\nax[1][0].set_title('val_acc')\n\nax[1][1].plot(logs['epoch'],logs['val_loss'], label='val_loss')\nax[1][1].set_title('val_loss')\n\nplt.show()\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"import pandas as pd\nimport matplotlib.pyplot as plt\n\nlogs = pd.read_csv(\"./log50\u70bc\u4e391123.csv\")\n\nfig, ax = plt.subplots(2, 1, figsize=(6, 6))\n\n# Plot accuracy\nax[0].plot(logs['epoch'], logs['acc'], label='Train Accuracy', color='blue')\nax[0].plot(logs['epoch'], logs['val_acc'], label='Validation Accuracy', color='orange')\nax[0].set_title('Train and Validation Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\nax[0].legend()\n\n# Plot loss\nax[1].plot(logs['epoch'], logs['loss'], label='Train Loss', color='blue')\nax[1].plot(logs['epoch'], logs['val_loss'], label='Validation Loss', color='orange')\nax[1].set_title('Train and Validation Loss')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nax[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'test_points_ids = list(set(test[\'mmsi\']))\n\nfor ids in test_points_ids[:1]:\n    y_pre = []\n    test_seq, test_label = createSequence(test.loc[test.mmsi == ids], windows, maxmin)\n\n    y_true = test_label\n    for i in range(len(test_seq)):\n        y_hat = model.predict(test_seq[i].reshape(1, windows, 4))\n        y_pre.append(y_hat[0])\n    y_pre = np.array(y_pre, dtype=\'float64\')\n\n    f_y_pre, f_y_true = FNormalizeMult(y_pre, y_true, maxmin)\n\n    print(f"\u6700\u5927\u503c: {max(f_y_pre[:, 4])}\\n\u6700\u5c0f\u503c: {min(f_y_pre[:, 4])}\\n\u5747\u503c: {np.mean(f_y_pre[:, 4])}\\n"\n          f"\u65b9\u5dee: {np.var(f_y_pre[:, 4])}\\n\u6807\u51c6\u5dee: {np.std(f_y_pre[:, 4])}\\n\u4e2d\u4f4d\u6570: {np.median(f_y_pre[:, 4])}")\n\n    # \u753b\u6d4b\u8bd5\u6837\u672c\u6570\u636e\u5e93\n    plt.figure(figsize=(16, 5))\n    plt.subplot(121)\n    plt.plot(f_y_true[:, 0], f_y_true[:, 1], "ro", markersize=6,label=\'\u771f\u5b9e\u503c\')\n    plt.plot(f_y_pre[:, 0], f_y_pre[:, 1], "bo",markersize=4, label=\'\u9884\u6d4b\u503c\')\n#     bounds = [min(f_y_true[:, 0])-0.02,min(f_y_true[:, 1])-0.01,max(f_y_true[:, 0])+0.02,max(f_y_true[:, 1])+0.01]\n#     tbd.plot_map(plt,bounds,zoom = 16,style = 3)\n    plt.legend(fontsize=14)\n    plt.grid()\n    plt.xlabel("\u7ecf\u5ea6",fontsize=14)\n    plt.ylabel("\u7eac\u5ea6",fontsize=14)\n    plt.title("MMSI:",fontsize=17)\n\n    meanss = np.mean(f_y_pre[:, 4])\n    plt.subplot(122)\n    plt.bar(range(f_y_pre.shape[0]),f_y_pre[:, 4],label=\'\u8bef\u5dee\')\n    plt.plot([0,f_y_pre.shape[0]],[meanss,meanss],\'--r\',label="\u5747\u503c")\n    plt.title("\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u7684\u8bef\u5dee",fontsize=17)\n    plt.xlabel("\u8239\u8236\u8f68\u8ff9\u70b9",fontsize=14)\n    plt.ylabel("\u9884\u6d4b\u8bef\u5dee(KM)",fontsize=14)\n    plt.text(f_y_pre.shape[0]*1.01,meanss*0.96,round(meanss,4),fontsize=14,color=\'r\')\n    plt.grid()\n    plt.legend(fontsize=14)\n\n    plt.figure(figsize=(16, 6))\n    plt.subplot(121)\n    plt.plot(f_y_pre[:, 2], "b-", label=\'\u9884\u6d4b\u503c\')\n    plt.plot(f_y_true[:, 2], "r-", label=\'\u771f\u5b9e\u503c\')\n    plt.legend(fontsize=14)\n    plt.title("\u822a\u901f\u9884\u6d4b",fontsize=17)\n    plt.xlabel("\u8239\u8236\u8f68\u8ff9\u70b9",fontsize=14)\n    plt.ylabel("\u822a\u901f/\u8282",fontsize=14)\n    plt.grid()\n\n    plt.subplot(122)\n    plt.plot(f_y_pre[:, 3], "b-", label=\'\u9884\u6d4b\u503c\')\n    plt.plot(f_y_true[:, 3], "r-", label=\'\u771f\u5b9e\u503c\')\n    plt.legend(fontsize=14)\n    plt.title("\u822a\u5411\u9884\u6d4b",fontsize=17)\n    plt.xlabel("\u8239\u8236\u8f68\u8ff9\u70b9",fontsize=14)\n    plt.ylabel("\u822a\u5411/\u5ea6",fontsize=14)\n    plt.grid()\n    \n'})}),"\n",(0,r.jsx)(n.p,{children:"\u5faa\u73af\u9884\u6d4b"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"error_list = []\nfor ids in test_points_ids[:1]:\n    test_seq, test_label = createSequence(test.loc[test.mmsi == ids], windows, maxmin)\n    # \u8981\u9884\u6d4b\u7684\u65f6\u95f4\n    pre_time = 60\n    for start_id in range(test_seq.shape[0]-int(pre_time/2)):\n        # \u5355\u503c\u9884\u6d4b\n        y_pre=[]\n        y_true = []\n        pre_seq = test_seq[start_id]\n        # \u5faa\u73af\u9884\u6d4b\n        for i in range(int(pre_time/2)):\n            y_hat = model.predict(pre_seq.reshape(1, windows, 4))\n            y_pre.append(y_hat[0])\n            y_true.append(test_label[start_id+i])\n            # \u4e0b\u4e00\u4e2a\u6570\u7ec4\uff0c\u628a\u9884\u6d4b\u7684\u503c\u4f5c\u4e3a\u9884\u6d4b\u5e8f\u5217\u7684\u6700\u540e\u4e00\u4e2a\u503c\uff0c\u5b9e\u73b0\u5faa\u73af\u9884\u6d4b\n            pre_seq = np.insert(pre_seq, pre_seq.shape[0], y_pre[i], axis=0)[1:]\n\n        y_pre = np.array(y_pre, dtype='float64')\n        y_true = np.array(y_true, dtype='float64')\n        f_y_pre,f_y_true = FNormalizeMult(y_pre,y_true,maxmin)\n        error_list.append(list(f_y_pre[:,4]))\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u7ed8\u5236\u9884\u6d4b\u7ed3\u679c"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"b = np.zeros([len(error_list),len(max(error_list,key = lambda x: len(x)))])\nfor i,j in enumerate(error_list):\n    b[i][0:len(j)] = j\n\nsums = b.sum(axis=0)\nmaxx = b.max(axis=0)\nminx = []\nBiGRU_means = []\nfor col in range(b.shape[1]):\n    fzeros = b.shape[0] - list(b[:,col]).count(0.0)\n    minx.append(min(list(b[:fzeros,col])))\n    BiGRU_means.append(sums[col] / fzeros)\n\nplt.figure(figsize=(12,6))\n\nplt.plot(np.arange(2,2*(b.shape[1])+1,2),BiGRU_means,'-m',label='BiGRU\u5e73\u5747\u8bef\u5dee')\n# plt.plot(np.arange(2,2*(b.shape[1])+1,2),minx,'-g',label='\u6700\u5c0f\u8bef\u5dee')\n# plt.plot(np.arange(2,2*(b.shape[1])+1,2),maxx,'-y',label='\u6700\u5927\u8bef\u5dee')\nplt.xticks(np.arange(2,2*(b.shape[1])+1,2))\nplt.yticks(np.arange(0,max(maxx),0.1))\nplt.xlabel(\"\u65f6\u95f4/\u5206\u949f\",fontsize=14)\nplt.ylabel(\"\u8ddd\u79bb\u8bef\u5dee/\u5343\u7c73\",fontsize=14)\nplt.legend(fontsize=14)\nplt.grid()\nplt.title(\"\u6574\u6761\u8f68\u8ff9\u4e0a\u968f\u65f6\u95f4\u53d8\u5316\u7684\u9884\u6d4b\u8ddd\u79bb\u8bef\u5dee\",fontsize=17)\nplt.savefig('\u516d\u79cd\u6a21\u578b\u968f\u65f6\u95f4\u5e73\u5747\u8bef\u5dee\u5bf9\u6bd4.png')\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nmae = mean_absolute_error(f_y_true[:, 1], f_y_pre[:, 1])\nprint(f\"\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09: {mae}\")\nmse = mean_squared_error(f_y_true[:, 1], f_y_pre[:, 1])\nrmse = np.sqrt(mse)\nprint(f\"\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09: {rmse}\")\nr2 = r2_score(f_y_true[:, 1], f_y_pre[:, 1])\nprint(f\"R2\u5206\u6570\uff08R2_score\uff09: {r2}\")\n\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"plt.figure(figsize=(16,8))\nplt.subplot(121)\nplt.plot(f_y_pre[:, 0], f_y_pre[:, 1], \"-b\", label='\u9884\u6d4b\u503c')\nplt.plot(f_y_true[:, 0], f_y_true[:, 1], \"-r\", label='\u771f\u5b9e\u503c')\n# plt.plot(true_lables[:start_id, 0], true_lables[:start_id, 1], \"o\",color='#eef200', label='\u5386\u53f2\u4f4d\u7f6e')\n# bounds = [min(f_y_true[:, 0])-0.01,min(f_y_true[:, 1])-0.01,max(f_y_true[:, 0])+0.01,max(f_y_true[:, 1])+0.01]\n# tbd.plot_map(plt,bounds,zoom = 16,style = 3)\nplt.legend(fontsize=15)\nplt.title(f'\u9884\u6d4b\u6b65\u6570\u91cf={maxStep},\u5f00\u59cb\u4f4d\u7f6e={start_id}',fontsize=17)\nplt.title(f'\u771f\u5b9e\u8f68\u8ff9\u4e0e\u9884\u6d4b\u8f68\u8ff9',fontsize=17)\nplt.xlabel(\"\u7ecf\u5ea6\",fontsize=15)\nplt.ylabel(\"\u7eac\u5ea6\",fontsize=15)\nplt.grid()\n"})}),"\n",(0,r.jsx)(n.h4,{id:"BiLSTM",children:"BiLSTM"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u6dfb\u52a0\u4e86\u4e00\u4e2a\u53cc\u5411\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08Bidirectional LSTM\uff09\uff0c\u5176\u4e2d\u5305\u542b108\u4e2aLSTM\u5355\u5143\u3002"}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"input_shape"}),"\u53c2\u6570\u8bbe\u7f6e\u4e3a",(0,r.jsx)(n.code,{children:"(train_X.shape[1], train_X.shape[2])"}),"\uff0c\u8fd9\u610f\u5473\u7740\u7f51\u7edc\u7684\u8f93\u5165\u6570\u636e\u5f62\u72b6\u7531",(0,r.jsx)(n.code,{children:"train_X"}),"\u7684\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u51b3\u5b9a\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528Adam\u4f18\u5316\u5668\uff08",(0,r.jsx)(n.code,{children:"adam_v2.Adam"}),"\uff09\uff0c\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a0.01\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:["\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u8bbe\u7f6e\u4e3a\u5747\u65b9\u8bef\u5dee\uff08",(0,r.jsx)(n.code,{children:"mse"}),"\uff09\uff0c\u8bc4\u4f30\u6307\u6807\u8bbe\u7f6e\u4e3a\u51c6\u786e\u7387\uff08",(0,r.jsx)(n.code,{children:"'acc'"}),"\uff09"]}),"\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"ReduceLROnPlateau"}),"\u56de\u8c03\u51fd\u6570\u6765\u5728\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\u4e0d\u518d\u63d0\u5347\u65f6\u964d\u4f4e\u5b66\u4e60\u7387\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="BiLSTM"',children:"from keras.layers import Bidirectional\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    model.add(Bidirectional(LSTM(108, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False)))\n    # model.add(Dropout(0.3))\n    model.add(Dense(train_Y.shape[1]))\n    model.add(Activation(\"relu\"))\n    adam = adam_v2.Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    # Save the changes to the log\n    log = CSVLogger(f\"./log50\u70bc\u4e391.csv\", separator=\",\", append=True)\n    # Reducing learning rate on a plateau\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1,\n                               mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n    # Model training\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1,\n                  callbacks=[log, reduce])\n    # Evaluate with the test set\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    # Save the model\n    model.save(f\"./biLSTM_50_model\u70bc\u4e391.h5\")\n    # Print the neural network structure and count the parameters\n    model.summary()\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u8bad\u7ec3\u8fc7\u7a0b\u3001\u7ed8\u5236\u7ed3\u679c\u3001\u6a21\u578b\u9884\u6d4b\u3001\u9884\u6d4b\u7ed3\u679c\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"BP",children:"BP"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6a21\u578b\u521d\u59cb\u5316"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Sequential()"}),"\u521b\u5efa\u4e86\u4e00\u4e2a\u987a\u5e8f\u6a21\u578b\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Flatten\u5c42"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u6dfb\u52a0\u4e86\u4e00\u4e2a",(0,r.jsx)(n.code,{children:"Flatten"}),"\u5c42\uff0c\u7528\u4e8e\u5c06\u8f93\u5165\u6570\u636e\u5c55\u5e73\u6210\u4e00\u7ef4\u6570\u7ec4\uff0c\u4ee5\u9002\u5e94\u540e\u7eed\u7684\u5168\u8fde\u63a5\u5c42\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"input_shape"}),"\u53c2\u6570\u8bbe\u7f6e\u4e3a",(0,r.jsx)(n.code,{children:"(train_X.shape[1], train_X.shape[2])"}),"\uff0c\u8fd9\u610f\u5473\u7740\u7f51\u7edc\u7684\u8f93\u5165\u6570\u636e\u5f62\u72b6\u7531",(0,r.jsx)(n.code,{children:"train_X"}),"\u7684\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u51b3\u5b9a\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u5168\u8fde\u63a5\u5c42\uff08Dense\uff09"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u7b2c\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u670964\u4e2a\u5355\u5143\uff0c\u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\u3002"}),"\n",(0,r.jsx)(n.li,{children:"\u7b2c\u4e8c\u4e2a\u5168\u8fde\u63a5\u5c42\u670932\u4e2a\u5355\u5143\uff0c\u540c\u6837\u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\u3002"}),"\n",(0,r.jsxs)(n.li,{children:["\u8f93\u51fa\u5c42\u7684\u5355\u5143\u6570\u7b49\u4e8e",(0,r.jsx)(n.code,{children:"train_Y.shape[1]"}),"\uff0c\u5373\u76ee\u6807\u53d8\u91cf\u7684\u7ef4\u5ea6\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u4f7f\u7528Adam\u4f18\u5316\u5668\uff0c\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a0.01\u3002"}),"\n",(0,r.jsxs)(n.li,{children:["\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u8bbe\u7f6e\u4e3a\u5747\u65b9\u8bef\u5dee\uff08",(0,r.jsx)(n.code,{children:"mse"}),"\uff09\uff0c\u8bc4\u4f30\u6307\u6807\u8bbe\u7f6e\u4e3a\u51c6\u786e\u7387\uff08",(0,r.jsx)(n.code,{children:"'acc'"}),"\uff09\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u65e5\u5fd7\u8bb0\u5f55\u5668\uff08CSVLogger\uff09"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"CSVLogger"}),"\u6765\u8bb0\u5f55\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u65e5\u5fd7\u4fe1\u606f\uff0c\u4fdd\u5b58\u5230",(0,r.jsx)(n.code,{children:"./bp_50\u70bc\u4e39.csv"}),"\u6587\u4ef6\u4e2d\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u5b66\u4e60\u7387\u8c03\u6574\uff08ReduceLROnPlateau\uff09"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"ReduceLROnPlateau"}),"\u56de\u8c03\u51fd\u6570\u6765\u5728\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\u4e0d\u518d\u63d0\u5347\u65f6\u964d\u4f4e\u5b66\u4e60\u7387\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6a21\u578b\u8bad\u7ec3\uff08model.fit\uff09"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"model.fit"}),"\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\uff0c\u8bbe\u7f6e50\u4e2a\u8bad\u7ec3\u5468\u671f\uff08epochs\uff09\uff0c\u6bcf\u627932\u4e2a\u6837\u672c\uff0c\u5e76\u4e14\u4f7f\u752810%\u7684\u6570\u636e\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\u3002"]}),"\n",(0,r.jsx)(n.li,{children:"\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u4f7f\u7528\u65e5\u5fd7\u8bb0\u5f55\u5668\u548c\u5b66\u4e60\u7387\u8c03\u6574\u5668\u3002"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6a21\u578b\u8bc4\u4f30"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"model.evaluate"}),"\u65b9\u6cd5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\uff0c\u8f93\u51fa\u635f\u5931\u548c\u51c6\u786e\u7387\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6a21\u578b\u4fdd\u5b58"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4fdd\u5b58\u5230",(0,r.jsx)(n.code,{children:"./BP_50_model\u70bc\u4e39.h5"}),"\u6587\u4ef6\u4e2d\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6a21\u578b\u7ed3\u6784\u548c\u53c2\u6570\u7edf\u8ba1"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"model.summary()"}),"\u6253\u5370\u6a21\u578b\u7684\u7ed3\u6784\u548c\u53c2\u6570\u6570\u91cf\u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="BP\u795e\u7ecf\u7f51\u7edc"',children:"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    model.add(Flatten(input_shape=(train_X.shape[1], train_X.shape[2])))  # \u5c06\u6570\u636e\u5c55\u5e73\u4ee5\u9002\u5e94\u8f93\u5165\u5c42\n    model.add(Dense(64, activation='relu'))  # \u8f93\u5165\u5c42\n    model.add(Dense(32, activation='relu'))  # \u9690\u85cf\u5c42\n    model.add(Dense(train_Y.shape[1]))  # \u8f93\u51fa\u5c42\n\n    adam = Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    \n    log = CSVLogger(f\"./bp_50\u70bc\u4e39.csv\", separator=\",\", append=True)\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1, callbacks=[log, reduce])\n    \n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    \n    model.save(f\"./BP_50_model\u70bc\u4e39.h5\")\n    model.summary()\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"CG",children:"CNN-GRU"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4e24\u4e2a\u5377\u79ef\u5c42\u670964\u4e2a\u6ee4\u6ce2\u5668\uff0c\u6838\u5927\u5c0f\u4e3a2\uff0c\u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u5e76\u4e14\u8bbe\u7f6e",(0,r.jsx)(n.code,{children:"padding='same'"}),"\u4ee5\u4fdd\u6301\u8f93\u51fa\u5c3a\u5bf8\u4e0e\u8f93\u5165\u76f8\u540c"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"MaxPooling1D"}),"\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\uff0c\u7528\u4e8e\u964d\u4f4e\u7279\u5f81\u7ef4\u5ea6\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Reshape"}),"\u5c42\u5c06\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u51fa\u91cd\u5851\u4e3a",(0,r.jsx)(n.code,{children:"(1, dense1.shape[1])"}),"\u7684\u5f62\u72b6\uff0c\u4ee5\u9002\u5e94GRU\u5c42\u7684\u8f93\u5165\u8981\u6c42\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u7b2c\u4e00\u4e2a",(0,r.jsx)(n.code,{children:"GRU"}),"\u5c42\u6709108\u4e2a\u5355\u5143\uff0c\u8fd4\u56de\u5e8f\u5217\u3002\u7b2c\u4e8c\u4e2a",(0,r.jsx)(n.code,{children:"GRU"}),"\u5c42\u4e0e\u7b2c\u4e00\u4e2a\u914d\u7f6e\u76f8\u540c\u3002\u7b2c\u4e09\u4e2a",(0,r.jsx)(n.code,{children:"GRU"}),"\u5c42\u6709108\u4e2a\u5355\u5143\uff0c\u4e0d\u8fd4\u56de\u5e8f\u5217\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="CNN-GRU"',children:"from keras.models import Model\nfrom keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, GRU, Reshape, Add, Attention\nfrom keras.optimizers import Adam\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau\nimport numpy as np\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    input_layer = Input(shape=(train_X.shape[1], train_X.shape[2]))\n    conv1 = Conv1D(filters=64, kernel_size=2, activation='relu', padding='same')(input_layer)\n    conv2 = Conv1D(filters=64, kernel_size=2, activation='relu', padding='same')(conv1)\n    max_pooling = MaxPooling1D(pool_size=2)(conv2)\n    flatten = Flatten()(max_pooling)\n    dense1 = Dense(100, activation='relu')(flatten)\n    \n    reshaped = Reshape((1, dense1.shape[1]))(dense1)\n\n\n    gru1 = GRU(108, return_sequences=True)(reshaped)\n#     gru1_dropout = Dropout(0.1)(gru1)  # Adding Dropout after the first GRU layer\n    gru2 = GRU(108, return_sequences=True)(gru1)\n    gru3 = GRU(108, return_sequences=False)(gru2)\n    dense2 = Dense(50, activation='relu')(gru3)\n    output_layer = Dense(train_Y.shape[1], activation='relu')(dense2)\n\n    model = Model(inputs=input_layer, outputs=output_layer)\n\n    # \u8bbe\u7f6e\u4f18\u5316\u5668\n    adam = Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n\n    # \u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u65e5\u5fd7\n    log = CSVLogger(f\"./CNN_GRU_log.csv\", separator=\",\", append=True)\n\n    # \u8bbe\u7f6e\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n\n    # \u5f00\u59cb\u6a21\u578b\u8bad\u7ec3\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1, callbacks=[log, reduce])\n\n    # \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./CNN_GRU_model.h5\")\n\n    # \u6253\u5370\u6a21\u578b\u7ed3\u6784\u548c\u53c2\u6570\u7edf\u8ba1\n    model.summary()\n\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"CL",children:"CNN-LSTM"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Input"}),"\u5c42\u5b9a\u4e49\u4e86\u6a21\u578b\u7684\u8f93\u5165\u5f62\u72b6\uff0c\u5373",(0,r.jsx)(n.code,{children:"(train_X.shape[1], train_X.shape[2])"}),"\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u7b2c\u4e00\u4e2a",(0,r.jsx)(n.code,{children:"Conv1D"}),"\u5c42\u670932\u4e2a\u6ee4\u6ce2\u5668\uff0c\u6838\u5927\u5c0f\u4e3a2\uff0c\u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u5e76\u4e14\u8bbe\u7f6e",(0,r.jsx)(n.code,{children:"padding='same'"}),"\u4ee5\u4fdd\u6301\u8f93\u51fa\u5c3a\u5bf8\u4e0e\u8f93\u5165\u76f8\u540c\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"MaxPooling1D"}),"\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\uff0c\u7528\u4e8e\u964d\u4f4e\u7279\u5f81\u7ef4\u5ea6\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Dropout"}),"\u5c42\uff0c\u4e22\u5f03\u7387\u4e3a0.2\uff0c\u7528\u4e8e\u51cf\u5c11\u8fc7\u62df\u5408\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Reshape"}),"\u5c42\u5c06\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u51fa\u91cd\u5851\u4e3a",(0,r.jsx)(n.code,{children:"(1, dense1.shape[1])"}),"\u7684\u5f62\u72b6\uff0c\u4ee5\u9002\u5e94LSTM\u5c42\u7684\u8f93\u5165\u8981\u6c42\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"LSTM"}),"\u5c42\uff0c\u6709100\u4e2a\u5355\u5143\uff0c\u4e0d\u8fd4\u56de\u5e8f\u5217\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Model"}),"\u7c7b\u6784\u5efa\u6a21\u578b\uff0c\u8f93\u5165\u5c42\u4e3a",(0,r.jsx)(n.code,{children:"input_layer"}),"\uff0c\u8f93\u51fa\u5c42\u4e3a",(0,r.jsx)(n.code,{children:"output_layer"}),"\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from keras.models import Model\nfrom keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, GRU, Reshape, Add, Attention,Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau\nimport numpy as np\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    input_layer = Input(shape=(train_X.shape[1], train_X.shape[2]))\n    conv1 = Conv1D(filters=32, kernel_size=2, activation='relu', padding='same')(input_layer)\n    max_pooling = MaxPooling1D(pool_size=2)(conv1)\n    dropout = Dropout(0.2)(max_pooling)\n    conv2 = Conv1D(filters=32, kernel_size=2, activation='relu', padding='same')(dropout)\n#     max_pooling = MaxPooling1D(pool_size=2)(conv2)\n    flatten = Flatten()(max_pooling)\n#     residual1 = Add()([conv1, conv2])  # Adding the residual connection\n    dense1 = Dense(100, activation='relu')(flatten)\n#     dense2 = Dense(32, activation='relu')(dense1)\n#     dense3 = Dense(16, activation='relu')(dense2)\n    reshaped = Reshape((1, dense1.shape[1]))(dense1)\n\n    # Adding Attention layer after all the previous layers\n#     attention = Attention()([reshaped, reshaped])\n#     attended_input = Add()([reshaped, attention])\n    lstm1 = LSTM(100, return_sequences=False)(reshaped)\n#     lstm2 = LSTM(108, return_sequences=False)(lstm1)\n#     lstm = GRU(108, return_sequences=True)(attended_input)\n#     lstm_dropout = Dropout(0.2)(lstm)  # Adding Dropout after the first GRU layer\n#     gru2 = GRU(108, return_sequences=False)(gru1)\n    output_layer = Dense(train_Y.shape[1], activation='relu')(lstm1)\n\n    model = Model(inputs=input_layer, outputs=output_layer)\n\n    # \u8bbe\u7f6e\u4f18\u5316\u5668\n    adam = Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n\n    # \u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u65e5\u5fd7\n    log = CSVLogger(f\"./CNN_LSTM_log50_2.csv\", separator=\",\", append=True)\n\n    # \u8bbe\u7f6e\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n\n    # \u5f00\u59cb\u6a21\u578b\u8bad\u7ec3\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1, callbacks=[log, reduce])\n\n    # \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./CNN_LSTM_model_\u70bc\u4e392.h5\")\n\n    # \u6253\u5370\u6a21\u578b\u7ed3\u6784\u548c\u53c2\u6570\u7edf\u8ba1\n    model.summary()\n\n    return model\n\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"CLA",children:"CNN-LSTM-Att"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Attention"}),"\u5c42\u5bf9\u6700\u540e\u4e00\u4e2aLSTM\u5c42\u7684\u8f93\u51fa\u8fdb\u884c\u6ce8\u610f\u529b\u52a0\u6743\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Add"}),"\u5c42\u5c06\u6ce8\u610f\u529b\u52a0\u6743\u540e\u7684\u8f93\u51fa\u4e0e\u539f\u59cbLSTM\u8f93\u51fa\u76f8\u52a0\uff0c\u5f97\u5230\u589e\u5f3a\u7684\u8f93\u5165\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="CNN-LSTM-Attention"',children:"from keras.models import Model\nfrom keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, GRU, Reshape, Add, Attention, Bidirectional\nfrom keras.optimizers import Adam\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau\nimport numpy as np\nfrom tcn import TCN \ndef trainModel(train_X, train_Y, test_X, test_Y):\n    input_layer = Input(shape=(train_X.shape[1], train_X.shape[2]))\n    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n#     conv2 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(conv1)\n    lstm1 = LSTM(32, return_sequences=True,activation='tanh')(conv1)\n    lstm2 = LSTM(32, return_sequences=True,activation='tanh')(lstm1)\n    lstm3 = LSTM(32, return_sequences=False,activation='tanh')(lstm2)\n\n    attention = Attention()([lstm3, lstm3])\n    attended_input = Add()([lstm3, attention])\n\n#     biLSTM = Bidirectional(LSTM(108, return_sequences=False, activation='tanh'))(attended_input)\n#     gru1_dropout = Dropout(0.1)(gru1)  # Adding Dropout after the first GRU layer\n#     gru1 = GRU(489, return_sequences=True,activation='tanh')(attended_input)\n#     gru2 = GRU(30, return_sequences=False,activation='tanh')(gru1)\n#     dense2 = Dense(dense_neurons2, activation='relu')(bigru1)\n    output_layer = Dense(train_Y.shape[1], activation='relu')(attended_input)\n    model = Model(inputs=input_layer, outputs=output_layer)\n    adam = Adam(learning_rate=0.01)\n\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n\n    # \u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u65e5\u5fd7\n    log = CSVLogger(f\"./CNN-LSTM_A_log.csv\", separator=\",\", append=True)\n\n    # \u8bbe\u7f6e\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1, mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n\n    # \u5f00\u59cb\u6a21\u578b\u8bad\u7ec3\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1, callbacks=[log, reduce])\n\n\n    # \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./CNN-LSTM-_A_model.h5\")\n\n    # \u6253\u5370\u6a21\u578b\u7ed3\u6784\u548c\u53c2\u6570\u7edf\u8ba1\n    model.summary()\n\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"GRU",children:"GRU"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"Sequential()"}),"\u521b\u5efa\u4e86\u4e00\u4e2a\u987a\u5e8f\u6a21\u578b\u3002"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"GRU\u5c42"}),"\uff1a"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"\u6dfb\u52a0\u4e86\u4e00\u4e2aGRU\u5c42\uff0c\u5305\u542b108\u4e2a\u5355\u5143\u3002"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"input_shape"}),"\u53c2\u6570\u8bbe\u7f6e\u4e3a",(0,r.jsx)(n.code,{children:"(train_X.shape[1], train_X.shape[2])"}),"\uff0c\u8fd9\u610f\u5473\u7740\u7f51\u7edc\u7684\u8f93\u5165\u6570\u636e\u5f62\u72b6\u7531",(0,r.jsx)(n.code,{children:"train_X"}),"\u7684\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u51b3\u5b9a\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"return_sequences"}),"\u53c2\u6570\u8bbe\u7f6e\u4e3a",(0,r.jsx)(n.code,{children:"False"}),"\uff0c\u8868\u793a\u8fd9\u4e2aGRU\u5c42\u7684\u8f93\u51fa\u4e0d\u4f1a\u8fd4\u56de\u5e8f\u5217\uff0c\u800c\u662f\u8fd4\u56de\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\u3002"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="GRU"',children:"from keras.layers import GRU\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    model.add(GRU(108, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False))\n    # model.add(Dropout(0.3))\n    model.add(Dense(train_Y.shape[1]))\n    model.add(Activation(\"relu\"))\n    adam = adam_v2.Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    # \u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u548c\u7cbe\u786e\u5ea6\u7684\u53d8\u5316\n    log = CSVLogger(f\"./log50\u70bc\u4e393.csv\", separator=\",\", append=True)\n    # \u7528\u6765\u81ea\u52a8\u964d\u4f4e\u5b66\u4e60\u7387\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1,\n                               mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n\t# \u6a21\u578b\u8bad\u7ec3\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1,\n                  callbacks=[log, reduce])\n    # \u7528\u6d4b\u8bd5\u96c6\u8bc4\u4f30\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./GRU_50_model\u70bc\u4e393_.h5\")\n    # \u6253\u5370\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7edf\u8ba1\u53c2\u6570\u6570\u76ee\n    model.summary()\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"LSTM",children:"LSTM"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"equential()"}),"\uff1a\u521b\u5efa\u4e00\u4e2a\u987a\u5e8f\u6a21\u578b\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"LSTM(108, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False)"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2aLSTM\u5c42\uff0c\u6709108\u4e2a\u5355\u5143\uff0c\u8f93\u5165\u5f62\u72b6\u7531",(0,r.jsx)(n.code,{children:"train_X"}),"\u7684\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u786e\u5b9a\uff0c",(0,r.jsx)(n.code,{children:"return_sequences=False"}),"\u8868\u793aLSTM\u5c42\u7684\u8f93\u51fa\u4e0d\u4f1a\u8fd4\u56de\u5e8f\u5217\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"Dense(train_Y.shape[1])"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u7684\u6570\u91cf\u7531",(0,r.jsx)(n.code,{children:"train_Y"}),"\u7684\u7b2c\u4e8c\u7ef4\u5ea6\u786e\u5b9a\u3002"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:'Activation("relu")'}),"\uff1a\u6fc0\u6d3b\u51fd\u6570\u8bbe\u7f6e\u4e3aReLU."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="LSTM"',children:"def trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    model.add(LSTM(108, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False))\n    # model.add(Dropout(0.3))\n    model.add(Dense(train_Y.shape[1]))\n    model.add(Activation(\"relu\"))\n    adam = adam_v2.Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    log = CSVLogger(f\"./log30\u70bc\u4e391.csv\", separator=\",\", append=True)\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1,\n                               mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n\n    model.fit(train_X, train_Y, epochs=30, batch_size=32, verbose=1, validation_data=(val_X, val_Y), callbacks=[log, reduce])\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    model.save(f\"./lstm_30_model\u70bc\u4e391.h5\")\n    # \u6253\u5370\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7edf\u8ba1\u53c2\u6570\u6570\u76ee\n    model.summary()\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"RL",children:"RNN-LSTM"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"Sequential()"}),"\uff1a\u521b\u5efa\u4e00\u4e2a\u987a\u5e8f\u6a21\u578b\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"SimpleRNN(60, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True)"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2aSimpleRNN\u5c42\uff0c\u670960\u4e2a\u5355\u5143\uff0c\u8f93\u5165\u5f62\u72b6\u7531",(0,r.jsx)(n.code,{children:"train_X"}),"\u7684\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u786e\u5b9a\uff0c",(0,r.jsx)(n.code,{children:"return_sequences=True"}),"\u8868\u793a\u8f93\u51fa\u5e8f\u5217\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"LSTM(60, return_sequences=False)"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2aLSTM\u5c42\uff0c\u670960\u4e2a\u5355\u5143\uff0c",(0,r.jsx)(n.code,{children:"return_sequences=False"}),"\u8868\u793a\u8f93\u51fa\u4e0d\u662f\u5e8f\u5217\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"Dense(train_Y.shape[1])"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u7531",(0,r.jsx)(n.code,{children:"train_Y"}),"\u7684\u7b2c\u4e8c\u7ef4\u5ea6\u786e\u5b9a\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'Activation("relu")'}),"\uff1a\u6fc0\u6d3b\u51fd\u6570\u8bbe\u7f6e\u4e3aReLU\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="RNN-LSTM"',children:"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GRU, LSTM, Dense, Activation,SimpleRNN\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import CSVLogger, ReduceLROnPlateau\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    model.add(SimpleRNN(60, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n    model.add(LSTM(60, return_sequences=False))\n    # model.add(Dropout(0.3))\n    model.add(Dense(train_Y.shape[1]))\n    model.add(Activation(\"relu\"))\n    adam = Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    # \u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u548c\u7cbe\u786e\u5ea6\u7684\u53d8\u5316\n    log = CSVLogger(f\"./RNN_LSTM_log50_2.csv\", separator=\",\", append=True)\n    # \u7528\u6765\u81ea\u52a8\u964d\u4f4e\u5b66\u4e60\u7387\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1,\n                               mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n    # \u6a21\u578b\u8bad\u7ec3\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.1,\n                  callbacks=[log, reduce])\n    # \u7528\u6d4b\u8bd5\u96c6\u8bc4\u4f30\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./RNN_LSTM_model2.h5\")\n    # \u6253\u5370\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7edf\u8ba1\u53c2\u6570\u6570\u76ee\n    model.summary()\n    return model\n\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"RLA",children:"RNN-LSTM-Att"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u8f93\u5165\u6570\u636e\u9996\u5148\u901a\u8fc7\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff08",(0,r.jsx)(n.code,{children:"Attention"}),"\u5c42\uff09\uff0c\u8fd9\u4e2a\u5c42\u4f1a\u8ba1\u7b97\u8f93\u5165\u6570\u636e\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u6743\u91cd\u5e94\u7528\u5230\u8f93\u5165\u6570\u636e\u4e0a\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:["\u81ea\u6ce8\u610f\u529b\u5c42\u7684\u8f93\u51fa\u88ab\u9001\u5165\u4e00\u4e2aLSTM\u5c42\uff0c\u8fd9\u4e2aLSTM\u5c42\u670964\u4e2a\u795e\u7ecf\u5143\uff0c\u4e0d\u8fd4\u56de\u5e8f\u5217\uff08",(0,r.jsx)(n.code,{children:"return_sequences=False"}),"\uff09\uff0c\u4f7f\u7528\u53cc\u66f2\u6b63\u5207\u6fc0\u6d3b\u51fd\u6570\uff08",(0,r.jsx)(n.code,{children:"'tanh'"}),"\uff09"]}),"\n",(0,r.jsx)(n.li,{children:"\u4e3a\u4e86\u51cf\u5c11\u8fc7\u62df\u5408\uff0cLSTM\u5c42\u7684\u8f93\u51fa\u901a\u8fc7\u4e00\u4e2aDropout\u5c42\uff0c\u4e22\u5f03\u7387\u4e3a0.2\u3002"}),"\n",(0,r.jsx)(n.li,{children:"Dropout\u5c42\u7684\u8f93\u51fa\u8fde\u63a5\u5230\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u8fd9\u4e2a\u5c42\u670964\u4e2a\u795e\u7ecf\u5143\uff0c\u540c\u6837\u4f7f\u7528\u53cc\u66f2\u6b63\u5207\u6fc0\u6d3b\u51fd\u6570\u3002"}),"\n",(0,r.jsxs)(n.li,{children:["\u6700\u7ec8\uff0c\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u51fa\u88ab\u9001\u5165\u8f93\u51fa\u5c42\uff0c\u8fd9\u4e2a\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\u7531",(0,r.jsx)(n.code,{children:"train_Y"}),"\u7684\u7b2c\u4e8c\u7ef4\u5ea6\u51b3\u5b9a\uff0c\u4e5f\u4f7f\u7528\u53cc\u66f2\u6b63\u5207\u6fc0\u6d3b\u51fd\u6570\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:["\u6a21\u578b\u4f7f\u7528Adam\u4f18\u5316\u5668\uff0c\u5b66\u4e60\u7387\u4e3a0.01\uff0c\u635f\u5931\u51fd\u6570\u4e3a\u5747\u65b9\u8bef\u5dee\uff08",(0,r.jsx)(n.code,{children:"'mse'"}),"\uff09\uff0c\u5e76\u4e14\u76d1\u63a7\u51c6\u786e\u7387\uff08",(0,r.jsx)(n.code,{children:"'acc'"}),"\uff09"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="RNN-LSTM-Attention"',children:"#\u6a21\u578b\u6784\u5efa\nimport tensorflow as tf\nfrom tensorflow.keras import layers,Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Layer\nfrom keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D, Dropout, Attention, Concatenate,LayerNormalization\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * np.exp(-0.1)\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    input_layer = layers.Input(shape=(train_X.shape[1], train_X.shape[2]))\n    #\u795e\u7ecf\u5143\uff08\u5377\u79ef\u6838\uff0920\u4e2a\uff0c\u5377\u79ef\u6838\u5927\u5c0f6\uff0c\u81a8\u80c0\u5927\u5c0f\u4e3a2\u7684\u6b21\u65b9\n    #t=TCN(return_sequences=True,nb_filters=64,kernel_size=5,dilations=[2 ** i for i in range(9)])(input_layer)\n    \n    # Step 2: Attention Mechanism\n    self_attention_input = input_layer\n\n    # \u6ce8\u610f\u529b\u5c42\u8ba1\u7b97\n    atten = Attention()([self_attention_input, self_attention_input])\n    lstm = LSTM(64, return_sequences=False,activation='tanh')(atten)\n    drop = Dropout(0.2)(lstm)\n    dense1=Dense(64,activation='tanh')(drop)\n    output_layer=Dense(train_Y.shape[1],activation='tanh')(dense1)\n    model = Model(inputs=input_layer,outputs=output_layer)\n    adam = Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    log = CSVLogger(f\"./Atten-LSTM_log.csv\", separator=\",\", append=True)\n    # \u7528\u6765\u81ea\u52a8\u964d\u4f4e\u5b66\u4e60\u7387\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1,\n                               mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n    lrs = LearningRateScheduler(scheduler)\n    # \u5f00\u59cb\u6a21\u578b\u8bad\u7ec3\n    model.fit(train_X, train_Y, epochs=50, batch_size=64, verbose=1, validation_split=0.2, callbacks=[log])\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    model.save(f\"D:/jupyter/LSTM_ship/Liuxin/Atten-LSTM/Atten-LSTM_model.h5\")\n    # \u6253\u5370\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7edf\u8ba1\u53c2\u6570\u6570\u76ee\n    model.summary()\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"TABL",children:"TCN-ABiLSTM"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u5168\u5c40\u6ce8\u610f\u529b\u673a\u5236"}),"\uff1a","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u5b9a\u4e49\u4e86\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684",(0,r.jsx)(n.code,{children:"GlobalAttention"}),"\u5c42\uff0c\u8be5\u5c42\u8ba1\u7b97\u8f93\u5165\u7684query\u548cvalue\u4e4b\u95f4\u7684\u70b9\u79ef\uff0c\u7136\u540e\u5e94\u7528softmax\u51fd\u6570\u83b7\u53d6\u6743\u91cd\uff0c\u6700\u540e\u8ba1\u7b97\u52a0\u6743\u7684value\u3002"]}),"\n",(0,r.jsx)(n.li,{children:"\u8f93\u5165\u5c42\u7684\u6570\u636e\u901a\u8fc7\u4e09\u4e2a\u5168\u8fde\u63a5\u5c42\uff08Dense\uff09\u5206\u522b\u8f6c\u6362\u4e3aquery\u3001key\u548cvalue\u3002"}),"\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528",(0,r.jsx)(n.code,{children:"GlobalAttention"}),"\u5c42\u5904\u7406query\u548cvalue\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u673a\u5236\u7684\u8f93\u51fa\u3002"]}),"\n",(0,r.jsx)(n.li,{children:"\u5c06\u6ce8\u610f\u529b\u8f93\u51fa\u4e0e\u539f\u59cb\u8f93\u5165\u5c42\u8fdb\u884c\u62fc\u63a5\u3002"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u53cc\u5411\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08Bi-LSTM\uff09"}),"\uff1a\u62fc\u63a5\u540e\u7684\u8f93\u51fa\u88ab\u9001\u5165\u4e00\u4e2a\u53cc\u5411LSTM\u5c42\uff0c\u8be5\u5c42\u670964\u4e2a\u795e\u7ecf\u5143\uff0c\u4e0d\u8fd4\u56de\u5e8f\u5217\uff08",(0,r.jsx)(n.code,{children:"return_sequences=False"}),"\uff09\uff0c\u4f7f\u7528\u53cc\u66f2\u6b63\u5207\u6fc0\u6d3b\u51fd\u6570\uff08",(0,r.jsx)(n.code,{children:"'tanh'"}),"\uff09\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="TCN-ABiLSTM"',children:"#\u6a21\u578b\u6784\u5efa\nimport tensorflow as tf\nfrom tensorflow.keras import layers,Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Layer\nfrom keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D, Dropout, Attention, Concatenate,LayerNormalization\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * np.exp(-0.1)\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    \n    # Step 1: TCN\n    input_layer = layers.Input(shape=(train_X.shape[1], train_X.shape[2]))\n    #\u795e\u7ecf\u5143\uff08\u5377\u79ef\u6838\uff0920\u4e2a\uff0c\u5377\u79ef\u6838\u5927\u5c0f6\uff0c\u81a8\u80c0\u5927\u5c0f\u4e3a2\u7684\u6b21\u65b9\n    #t=TCN(return_sequences=True,nb_filters=64,kernel_size=5,dilations=[2 ** i for i in range(9)])(input_layer)\n    \n    # Step 2: Attention Mechanism\n    class GlobalAttention(Layer):\n        def __init__(self, **kwargs):\n            super(GlobalAttention, self).__init__(**kwargs)\n    \n        def call(self, inputs):\n            query, value = inputs\n        \n            # Compute the dot product between query and key\n            score = tf.matmul(query, value, transpose_b=True)\n            weights = tf.nn.softmax(score, axis=-1)\n        \n            # Compute the weighted sum of the values\n            attention_output = tf.matmul(weights, value)\n        \n            return attention_output\n\n\n    # Apply Dense layers to prepare query, key, and value\n    query = Dense(64)(input_layer)\n    key = Dense(64)(input_layer)\n    value = Dense(64)(input_layer)\n\n    # Apply the global attention mechanism\n    attention_output = GlobalAttention()([query, value])\n\n    # Concatenate the attention output with the TCN output\n    atten = Concatenate()([input_layer, attention_output])\n\n    #att = Attention()([t, t])\n    #atten = Concatenate()([t, att])\n    \n    #Bi-LSTM\u5c42\n    bi_lstm = Bidirectional(LSTM(64, return_sequences=False,activation='tanh'))(atten)\n    drop = Dropout(0.2)(bi_lstm)\n    \n    # Step 3: \u5168\u8fde\u63a5\u5c42\n    dense1=Dense(50,activation='tanh')(drop)\n    output_layer=Dense(train_Y.shape[1],activation='tanh')(dense1)\n    model = Model(inputs=input_layer,outputs=output_layer)\n    adam = Adam(learning_rate=0.01)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])\n    # \u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u548c\u7cbe\u786e\u5ea6\u7684\u53d8\u5316\n    log = CSVLogger(f\"./log.csv\", separator=\",\", append=True)\n    # \u7528\u6765\u81ea\u52a8\u964d\u4f4e\u5b66\u4e60\u7387\n    reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, verbose=1,\n                               mode='auto', min_delta=0.001, cooldown=0, min_lr=0.001)\n    lrs = LearningRateScheduler(scheduler)\n    # \u6a21\u578b\u8bad\u7ec3\n    model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=1, validation_split=0.2,\n                  callbacks=[log, reduce,lrs])\n    # \u7528\u6d4b\u8bd5\u96c6\u8bc4\u4f30\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./model.h5\")\n    # \u6253\u5370\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7edf\u8ba1\u53c2\u6570\u6570\u76ee\n    model.summary()\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"EDL",children:"\u7f16\u7801\u89e3\u7801-LSTM"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u7f16\u7801\u5668\uff08Encoder\uff09\u90e8\u5206\uff1a"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u8f93\u5165\u5c42"}),"\uff1a",(0,r.jsx)(n.code,{children:"encoder_inputs"})," \u662f\u7f16\u7801\u5668\u7684\u8f93\u5165\uff0c\u5176\u5f62\u72b6\u7531 ",(0,r.jsx)(n.code,{children:"train_X"})," \u7684\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u51b3\u5b9a\uff0c\u5373 ",(0,r.jsx)(n.code,{children:"shape=(train_X.shape[1], train_X.shape[2])"}),"\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LSTM\u5c42"}),"\uff1a",(0,r.jsx)(n.code,{children:"encoder_lstm"})," \u662f\u4e00\u4e2a LSTM \u5c42\uff0c\u6709 100 \u4e2a\u795e\u7ecf\u5143\uff0c\u5e76\u4e14\u8fd4\u56de\u72b6\u6001\u3002\u8fd9\u4e2a\u5c42\u63a5\u6536 ",(0,r.jsx)(n.code,{children:"encoder_inputs"})," \u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u8f93\u51fa\u5e8f\u5217\u3001\u9690\u85cf\u72b6\u6001 ",(0,r.jsx)(n.code,{children:"state_h"})," \u548c\u7ec6\u80de\u72b6\u6001 ",(0,r.jsx)(n.code,{children:"state_c"}),"\u3002\u8fd9\u4e24\u4e2a\u72b6\u6001\u5c06\u88ab\u7528\u4f5c\u89e3\u7801\u5668\u7684\u521d\u59cb\u72b6\u6001\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u72b6\u6001\u8f93\u51fa"}),"\uff1a",(0,r.jsx)(n.code,{children:"encoder_states"})," \u662f\u4e00\u4e2a\u5305\u542b\u9690\u85cf\u72b6\u6001\u548c\u7ec6\u80de\u72b6\u6001\u7684\u5217\u8868\uff0c\u5c06\u88ab\u4f20\u9012\u7ed9\u89e3\u7801\u5668\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u89e3\u7801\u5668\uff08Decoder\uff09\u90e8\u5206\uff1a"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u8f93\u5165\u5c42"}),"\uff1a",(0,r.jsx)(n.code,{children:"decoder_inputs"})," \u662f\u89e3\u7801\u5668\u7684\u8f93\u5165\uff0c\u5176\u5f62\u72b6\u7531 ",(0,r.jsx)(n.code,{children:"train_Y"})," \u7684\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u51b3\u5b9a\uff0c\u5373 ",(0,r.jsx)(n.code,{children:"shape=(train_Y.shape[1], train_Y.shape[2])"}),"\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LSTM\u5c42"}),"\uff1a",(0,r.jsx)(n.code,{children:"decoder_lstm"})," \u662f\u4e00\u4e2a LSTM \u5c42\uff0c\u6709 100 \u4e2a\u795e\u7ecf\u5143\uff0c\u8fd4\u56de\u5e8f\u5217\u548c\u72b6\u6001\u3002\u8fd9\u4e2a\u5c42\u63a5\u6536 ",(0,r.jsx)(n.code,{children:"decoder_inputs"})," \u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u4f7f\u7528\u7f16\u7801\u5668\u7684\u6700\u7ec8\u72b6\u6001\u4f5c\u4e3a\u521d\u59cb\u72b6\u6001\u3002\u5b83\u8f93\u51fa\u5e8f\u5217\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u5168\u8fde\u63a5\u5c42"}),"\uff1a",(0,r.jsx)(n.code,{children:"decoder_dense"})," \u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff08Dense\uff09\uff0c\u6709 ",(0,r.jsx)(n.code,{children:"train_Y.shape[2]"})," \u4e2a\u795e\u7ecf\u5143\uff0c\u4f7f\u7528 ReLU \u6fc0\u6d3b\u51fd\u6570\u3002\u8fd9\u4e2a\u5c42\u63a5\u6536 LSTM \u5c42\u7684\u8f93\u51fa\uff0c\u5e76\u8f93\u51fa\u6700\u7ec8\u7684\u9884\u6d4b\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u6a21\u578b\u6784\u5efa\uff1a"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u4f7f\u7528 ",(0,r.jsx)(n.code,{children:"Model"})," \u7c7b\u6784\u5efa\u6a21\u578b\uff0c\u8f93\u5165\u662f\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u8f93\u5165\uff0c\u8f93\u51fa\u662f\u89e3\u7801\u5668\u7684\u8f93\u51fa\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title = "encoder-decoder-LSTM"',children:"def trainModel(train_X, train_Y, test_X, test_Y):\n    # Encoder\u90e8\u5206\n    encoder_inputs = Input(shape=(train_X.shape[1], train_X.shape[2]))\n    encoder_lstm = LSTM(100, return_state=True)\n    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n    encoder_states = [state_h, state_c]\n\n    # Decoder\u90e8\u5206\n    decoder_inputs = Input(shape=(train_Y.shape[1], train_Y.shape[2]))  # \u76ee\u6807\u5e8f\u5217\u7684\u5f62\u72b6\n    decoder_lstm = LSTM(100, return_sequences=True, return_state=True)\n    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n    decoder_dense = Dense(train_Y.shape[2], activation='relu')\n    decoder_outputs = decoder_dense(decoder_outputs)\n\n    # \u6784\u5efa\u6a21\u578b\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n    # \u7f16\u8bd1\u6a21\u578b\n    model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n\n    # \u8bb0\u5f55\u65e5\u5fd7\n    log = CSVLogger(f\"./log_encoder_decoder_lstm.csv\", separator=\",\", append=True)\n\n    # \u8bad\u7ec3\u6a21\u578b\n    model.fit([train_X, train_Y], train_Y, epochs=200, batch_size=64, verbose=1, validation_split=0.1, callbacks=[log])\n\n    # \u6a21\u578b\u8bc4\u4f30\n    loss, acc = model.evaluate([test_X, test_Y], test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./encoder_decoder_lstm_model.h5\")\n\n    # \u6253\u5370\u6a21\u578b\u7ed3\u6784\n    model.summary()\n\n    return model\n"})}),"\n",(0,r.jsxs)(n.p,{children:["\u5176\u4f59\u8fc7\u7a0b\u53c2\u4e0a",(0,r.jsx)(n.a,{href:"#BiGRU",children:"BiGRU"})]}),"\n",(0,r.jsx)(n.h4,{id:"SG",children:"STA-GRU"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u81ea\u5b9a\u4e49\u6ce8\u610f\u529b\u6a21\u5757\uff08AttentionBlock\uff09\uff1a"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u521d\u59cb\u5316"}),"\uff1a",(0,r.jsx)(n.code,{children:"AttentionBlock"})," \u7c7b\u7ee7\u627f\u81ea ",(0,r.jsx)(n.code,{children:"Layer"}),"\uff0c\u521d\u59cb\u5316\u65f6\u63a5\u6536\u8f93\u5165\u7ef4\u5ea6 ",(0,r.jsx)(n.code,{children:"input_dim"}),"\uff0c\u5e76\u5b9a\u4e49\u4e00\u4e2a ",(0,r.jsx)(n.code,{children:"Dense"})," \u5c42\u7528\u4e8e\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u6fc0\u6d3b\u51fd\u6570\u4e3a ",(0,r.jsx)(n.code,{children:"softmax"}),"\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u524d\u5411\u4f20\u64ad"}),"\uff1a",(0,r.jsx)(n.code,{children:"call"})," \u65b9\u6cd5\u63a5\u6536\u8f93\u5165 ",(0,r.jsx)(n.code,{children:"inputs"}),"\uff0c\u4f7f\u7528 ",(0,r.jsx)(n.code,{children:"Dense"})," \u5c42\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u7136\u540e\u4f7f\u7528 ",(0,r.jsx)(n.code,{children:"Multiply"})," \u5c42\u5c06\u6ce8\u610f\u529b\u6743\u91cd\u5e94\u7528\u5230\u8f93\u5165\u4e0a\uff0c\u8f93\u51fa\u52a0\u6743\u540e\u7684\u7ed3\u679c\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u914d\u7f6e\u83b7\u53d6"}),"\uff1a",(0,r.jsx)(n.code,{children:"get_config"})," \u65b9\u6cd5\u7528\u4e8e\u5e8f\u5217\u5316\u5c42\u7684\u914d\u7f6e\uff0c\u4ee5\u4fbf\u540e\u7eed\u53ef\u4ee5\u91cd\u5efa\u76f8\u540c\u7684\u5c42\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u6a21\u578b\u6784\u5efa\uff1a"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6ce8\u610f\u529b\u6a21\u5757"}),"\uff1a\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684 ",(0,r.jsx)(n.code,{children:"AttentionBlock"})," \u4f5c\u4e3a\u6a21\u578b\u7684\u7b2c\u4e00\u5c42\uff0c\u8f93\u5165\u7ef4\u5ea6\u4e3a ",(0,r.jsx)(n.code,{children:"train_X.shape[2]"}),"\uff0c\u8f93\u5165\u5f62\u72b6\u4e3a ",(0,r.jsx)(n.code,{children:"(train_X.shape[1], train_X.shape[2])"}),"\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GRU\u5c42"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2a GRU \u5c42\uff0c\u6709100\u4e2a\u5355\u5143\uff0c\u4e0d\u8fd4\u56de\u5e8f\u5217\uff08",(0,r.jsx)(n.code,{children:"return_sequences=False"}),"\uff09\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dropout\u5c42"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2a Dropout \u5c42\uff0c\u4e22\u5f03\u7387\u4e3a0.5\uff0c\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u8f93\u51fa\u5c42"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff08Dense\uff09\uff0c\u8f93\u51fa\u7ef4\u5ea6\u4e0e\u6807\u7b7e ",(0,r.jsx)(n.code,{children:"train_Y"})," \u7684\u7b2c\u4e8c\u7ef4\u5ea6\u76f8\u540c\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6fc0\u6d3b\u51fd\u6570"}),"\uff1a\u5728\u8f93\u51fa\u5c42\u540e\u6dfb\u52a0 ReLU \u6fc0\u6d3b\u51fd\u6570\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="\u81ea\u5b9a\u4e49\u6ce8\u610f\u529b\u5c42\u7684GRU"',children:"class AttentionBlock(Layer):\n    def __init__(self, input_dim, **kwargs):\n        super(AttentionBlock, self).__init__(**kwargs)\n        self.input_dim = input_dim\n        # \u5b9a\u4e49 Dense \u5c42\u7528\u4e8e\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\n        self.attention_dense = Dense(input_dim, activation='softmax')\n\n    def call(self, inputs):\n        # \u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u4e0d\u8fdb\u884c\u8f6c\u7f6e\n        attention_weights = self.attention_dense(inputs)\n        # \u5e94\u7528\u6ce8\u610f\u529b\u6743\u91cd\u5230\u8f93\u5165\u4e0a\uff0c\u5f62\u72b6\u5fc5\u987b\u4e00\u81f4\n        output_attention = Multiply()([inputs, attention_weights])\n        return output_attention\n\n    def get_config(self):\n        config = super(AttentionBlock, self).get_config()\n        config.update({'input_dim': self.input_dim})\n        return config\n\ndef trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n\n   # \u4f7f\u7528\u81ea\u5b9a\u4e49\u7684 AttentionBlock \u66ff\u4ee3 Lambda \u5c42\n    model.add(AttentionBlock(input_dim=train_X.shape[2], input_shape=(train_X.shape[1], train_X.shape[2])))\n    \n    # GRU\u5c42\n    model.add(GRU(100, return_sequences=False))  # \u4f7f\u7528GRU\u5355\u5143\n    model.add(Dropout(0.5))  # Dropout\u5c42\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n    \n    # \u8f93\u51fa\u5c42\n    model.add(Dense(train_Y.shape[1]))  # \u8f93\u51fa\u5c42\uff0c\u8f93\u51fa\u7ef4\u5ea6\u4e0e\u6807\u7b7e\u7ef4\u5ea6\u76f8\u540c\n    model.add(Activation(\"relu\"))  # \u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\n\n    # \u4f7f\u7528Adam\u4f18\u5316\u5668\n    adam = Adam(learning_rate=0.001)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])  # \u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\n\n    # \u8bb0\u5f55\u8bad\u7ec3\u65e5\u5fd7\n    log = CSVLogger(f\"./log_sta_gru.csv\", separator=\",\", append=True)\n\n    # \u5f00\u59cb\u8bad\u7ec3\u6a21\u578b\n    model.fit(train_X, train_Y, epochs=200, batch_size=64, verbose=1, validation_split=0.1, callbacks=[log])\n\n    # \u6a21\u578b\u8bc4\u4f30\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n\n    # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./sta_gru_model.h5\")\n\n    # \u6253\u5370\u6a21\u578b\u7ed3\u6784\n    model.summary()\n\n    return model\n"})}),"\n",(0,r.jsx)(n.h4,{id:"SBL",children:"SW-BiLSTM"}),"\n",(0,r.jsx)(n.p,{children:"\u5305\u542b\u5377\u79ef\u5c42\u3001\u6700\u5927\u6c60\u5316\u5c42\u3001Dropout\u5c42\u3001\u53cc\u5411\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08Bi-LSTM\uff09\u548c\u5168\u8fde\u63a5\u8f93\u51fa\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u5377\u79ef\u5c42"}),"\uff1a\u6a21\u578b\u7684\u7b2c\u4e00\u5c42\u662f\u4e00\u7ef4\u5377\u79ef\u5c42\uff08",(0,r.jsx)(n.code,{children:"Conv1D"}),"\uff09\uff0c\u670964\u4e2a\u8fc7\u6ee4\u5668\uff08filters\uff09\uff0c\u6838\u5927\u5c0f\u4e3a3\uff0c\u4f7f\u7528\u201csame\u201d\u586b\u5145\u4ee5\u4fdd\u6301\u8f93\u51fa\u5c3a\u5bf8\u4e0e\u8f93\u5165\u76f8\u540c\uff0c\u6fc0\u6d3b\u51fd\u6570\u4e3aReLU\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6700\u5927\u6c60\u5316\u5c42"}),"\uff1a\u63a5\u7740\u662f\u4e00\u4e2a\u6700\u5927\u6c60\u5316\u5c42\uff08",(0,r.jsx)(n.code,{children:"MaxPooling1D"}),"\uff09\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\uff0c\u7528\u4e8e\u964d\u4f4e\u7279\u5f81\u7ef4\u5ea6\u5e76\u63d0\u53d6\u91cd\u8981\u7279\u5f81\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dropout\u5c42"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2aDropout\u5c42\uff0c\u4e22\u5f03\u7387\u4e3a0.5\uff0c\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u53cc\u5411LSTM\u5c42"}),"\uff1a\u4f7f\u7528 ",(0,r.jsx)(n.code,{children:"Bidirectional"})," \u5305\u88c5\u4e00\u4e2a LSTM \u5c42\uff0cLSTM\u5c42\u6709100\u4e2a\u5355\u5143\uff0c\u4e0d\u8fd4\u56de\u5e8f\u5217\uff08",(0,r.jsx)(n.code,{children:"return_sequences=False"}),"\uff09\uff0c\u7528\u4e8e\u5904\u7406\u5e8f\u5217\u6570\u636e\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u8f93\u51fa\u5c42"}),"\uff1a\u6dfb\u52a0\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff08Dense\uff09\uff0c\u8f93\u51fa\u7ef4\u5ea6\u4e0e\u6807\u7b7e ",(0,r.jsx)(n.code,{children:"train_Y"})," \u7684\u7ef4\u5ea6\u76f8\u540c\u3002"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"\u6fc0\u6d3b\u51fd\u6570"}),"\uff1a\u5728\u8f93\u51fa\u5c42\u540e\u6dfb\u52a0ReLU\u6fc0\u6d3b\u51fd\u6570\u3002"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",metastring:'title="SW-BiLSTM"',children:"def trainModel(train_X, train_Y, test_X, test_Y):\n    model = Sequential()\n    \n     # \u5f15\u5165\u5377\u79ef\u5c42\u4f5c\u4e3a\u6ed1\u52a8\u7a97\u53e3\u7279\u5f81\u63d0\u53d6\u5668\n    model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(train_X.shape[1], train_X.shape[2])))\n    model.add(MaxPooling1D(pool_size=2))  # \u6700\u5927\u6c60\u5316\u5c42\u51cf\u5c11\u7279\u5f81\u7ef4\u5ea6\n    model.add(Dropout(0.5))  # Dropout\u5c42\u9632\u6b62\u8fc7\u62df\u5408\n    \n    # \u4f7f\u7528\u53cc\u5411LSTM\uff08Bi-LSTM\uff09\n    model.add(Bidirectional(LSTM(100, return_sequences=False), input_shape=(train_X.shape[1], train_X.shape[2])))\n    \n    #\u8f93\u51fa\u5c42\n    model.add(Dense(train_Y.shape[1]))  # \u8f93\u51fa\u5c42\uff0c\u8f93\u51fa\u7ef4\u5ea6\u4e0e\u6807\u7b7e\u7ef4\u5ea6\u76f8\u540c\n    model.add(Activation(\"relu\"))  # \u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\n    \n    # \u4f7f\u7528\u4f18\u5316\u540e\u7684Adam\u4f18\u5316\u5668\n    adam = Adam(learning_rate=0.001)\n    model.compile(loss='mse', optimizer=adam, metrics=['acc'])  # \u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\n    \n    # \u8bb0\u5f55\u8bad\u7ec3\u65e5\u5fd7\n    log = CSVLogger(f\"./log_sw_bi_lstm.csv\", separator=\",\", append=True)\n  \n    # \u5f00\u59cb\u8bad\u7ec3\u6a21\u578b\uff0c\u76f8\u540c\u53c2\u6570\n    model.fit(train_X, train_Y, epochs=200, batch_size=64, verbose=1, validation_split=0.1, callbacks=[log])\n    \n    # \u6a21\u578b\u8bc4\u4f30\n    loss, acc = model.evaluate(test_X, test_Y, verbose=1)\n    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n    \n     # \u4fdd\u5b58\u6a21\u578b\n    model.save(f\"./sw_bi_lstm_model.h5\")\n    \n    # \u6253\u5370\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7edf\u8ba1\u53c2\u6570\u6570\u76ee\n    model.summary()\n    \n    return model\n"})})]})}function p(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>i});var s=t(6540);const r={},l=s.createContext(r);function a(e){const n=s.useContext(l);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);